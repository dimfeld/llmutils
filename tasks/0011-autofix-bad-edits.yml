goal: Implement an automatic retry mechanism in apply-llm-edits that asks the
  LLM to fix failed edits before falling back to interactive mode.
details: >
  When applying edits suggested by an LLM (especially diff-based edits), they
  sometimes fail due to context mismatches or incorrect formatting. Currently,
  `apply-llm-edits` either throws an error or enters an interactive mode to
  resolve these failures.


  This project aims to add an intermediate step: when edits fail, the tool will
  automatically construct a new prompt for the LLM. This prompt will include the
  original request context, the LLM's previous (failed) response, and detailed
  information about the edit failures. The LLM will be asked to provide a
  corrected set of edits. If these corrected edits *still* fail, the tool will
  then proceed to the interactive resolution mode (if enabled) or throw an
  error.


  **Core Steps:**


  1.  **Refactor:** Isolate the core edit application logic from the main
  `applyLlmEdits` function to allow reuse during retries.

  2.  **Failure Formatting:** Create a function to format the details of edit
  failures into a human-readable string suitable for inclusion in an LLM prompt.

  3.  **Original Context Retrieval:** Implement logic to retrieve the context of
  the original LLM request. This involves:
      *   Accepting the original prompt directly if available.
      *   Parsing the `<rmfilter_command>` tag from the LLM's output.
      *   Reading the cached `rmfilter` output (e.g., `repomix-output.xml`).
      *   Comparing the command arguments and potentially re-running `rmfilter` if the cache is stale.
  4.  **LLM Interaction:** Define an interface (e.g., a callback function) for
  `applyLlmEdits` to request a new completion from an external LLM.

  5.  **Retry Logic:** Integrate these components into `applyLlmEdits` to
  construct the retry prompt, call the LLM, and attempt to apply the new edits.

  6.  **Fallback:** Ensure the system falls back gracefully to interactive mode
  or error handling if the retry attempt also fails.
tasks:
  - title: 1 - Refactor Core Edit Application Logic
    description: >
      Extract the main edit processing logic from `applyLlmEdits` into a
      reusable internal function. This will facilitate calling the edit
      application process multiple times (initial attempt and retry attempt)
      without duplicating setup code.
    files:
      - src/apply-llm-edits/apply.ts
      - src/editor/types.ts
      - src/editor/diff-editor/parse.ts
      - src/editor/udiff-simple/parse.ts
      - src/editor/xml/parse_xml.ts
      - src/editor/whole-file/parse_raw_edits.ts
    steps:
      - prompt: >
          Refactor the `applyLlmEdits` function in
          `src/apply-llm-edits/apply.ts`.


          1.  Define a new internal asynchronous function `applyEditsInternal`
          within the same file. This function should encapsulate the core logic
          of applying edits based on the content and mode.

          2.  `applyEditsInternal` should accept parameters similar to
          `applyLlmEdits` but focused solely on the processing: `content:
          string`, `writeRoot: string`, `dryRun: boolean`, `mode?: 'diff' |
          'udiff' | 'xml' | 'whole'`.

          3.  `applyEditsInternal` should perform the mode detection (xml, diff,
          udiff, whole) based on the `mode` parameter or content analysis.

          4.  It should call the appropriate processing function
          (`processUnifiedDiff`, `processSearchReplace`, `processXmlContents`,
          `processRawFiles`).

          5.  It should return the `EditResult[]` if the mode produces results
          (diff modes), or `undefined` otherwise. It should *not* handle the
          interactive resolution or detailed failure printing/throwing logic
          yet. That will remain in the outer function for now.

          6.  Modify the existing `applyLlmEdits` function:
              *   It should still handle the initial setup (getting `writeRoot`).
              *   It should call `applyEditsInternal` to get the initial `results`.
              *   It should then contain the existing logic for handling `results`: checking for failures, handling auto-applied `notUnique` failures, deciding whether to enter interactive mode or print detailed failures and throw.
          7.  Ensure all necessary types (`EditResult`, `NoMatchFailure`,
          `NotUniqueFailure`, etc.) are imported correctly in `apply.ts`.

          8.  Update any internal calls within the refactored logic to use the
          correct parameters and return types.
        done: true
      - prompt: >
          Add unit tests for the new `applyEditsInternal` function in
          `src/apply-llm-edits/apply.ts`.


          1.  Create a new test file `src/apply-llm-edits/apply.test.ts`.

          2.  Import necessary modules: `test`, `expect`, `describe`, `jest`
          from `bun:test`, and the `applyEditsInternal` function (you might need
          to export it for testing or use `@ts-expect-error` if keeping it
          private). Also import mock functions or types if needed.

          3.  Mock the underlying edit processing functions
          (`processUnifiedDiff`, `processSearchReplace`, `processXmlContents`,
          `processRawFiles`) using `jest.mock` or `mock.module`. Make them
          return predictable results (e.g., sample `EditResult[]` for diff
          modes, or resolve successfully for whole-file modes).

          4.  Write test cases for `applyEditsInternal`:
              *   Test each mode ('diff', 'udiff', 'xml', 'whole') is correctly detected and the corresponding mock processor is called.
              *   Test automatic mode detection based on content (`<code_changes>`, `<<<<<<< SEARCH`, `--- ` + `@@`).
              *   Verify that the function returns the `EditResult[]` from the mocked diff processors.
              *   Verify that it returns `undefined` for whole-file modes.
              *   Ensure `dryRun` and `writeRoot` are passed correctly to the mocked processors.
        done: true
  - title: 2 - Format Failures for LLM Prompt
    description: >
      Create a function that takes the list of failed edits and generates a
      descriptive string summarizing the failures, suitable for instructing an
      LLM on what needs to be fixed.
    files:
      - src/apply-llm-edits/failures.ts
      - src/editor/types.ts
      - src/apply-llm-edits/apply.ts
    steps:
      - prompt: >
          In `src/apply-llm-edits/failures.ts`:


          1.  Import necessary types: `EditResult`, `NoMatchFailure`,
          `NotUniqueFailure`, `ClosestMatchResult` from `../editor/types.js`.

          2.  Import the `diff` library: `import * as diff from 'diff';`.

          3.  Create a new exported function `formatFailuresForLlm(failures:
          (NoMatchFailure | NotUniqueFailure)[]): string`.

          4.  This function should iterate through the `failures` array.

          5.  For each failure, generate a descriptive string including:
              *   The file path (`failure.filePath`).
              *   The type of failure ('No Exact Match' or 'Not Unique').
              *   The original text block that was supposed to be replaced (`failure.originalText`). Limit the displayed original text to a reasonable number of lines (e.g., first/last 5 lines if it's very long) to avoid excessive prompt length, adding an indicator like `... (trimmed) ...` if necessary.
              *   For 'noMatch' failures:
                  *   State that the text was not found.
                  *   If `failure.closestMatch` exists, include:
                      *   The closest matching text block (`failure.closestMatch.lines`). Limit lines similarly if needed.
                      *   The line range of the closest match (`failure.closestMatch.startLine` to `failure.closestMatch.endLine`).
                      *   Generate a diff between the `closestMatch.lines` and the `failure.originalText` using `diff.createPatch`. Format this diff clearly (e.g., indent lines, remove headers).
              *   For 'notUnique' failures:
                  *   State how many locations the text was found in (`failure.matchLocations.length`).
                  *   List the starting line number for each match location (`loc.startLine`).
                  *   Include a few lines of context around each match location (`loc.contextLines`).
          6.  Combine the descriptions for all failures into a single string,
          perhaps separated by newlines or markers. Start the string with a
          summary like "The following edit(s) failed to apply:".

          7.  Return the combined string.
        done: true
      - prompt: >
          Add unit tests for the `formatFailuresForLlm` function in
          `src/apply-llm-edits/failures.ts`.


          1.  Create a new test file `src/apply-llm-edits/failures.test.ts`.

          2.  Import necessary modules: `test`, `expect`, `describe` from
          `bun:test`, and the `formatFailuresForLlm` function. Also import the
          failure types (`NoMatchFailure`, `NotUniqueFailure`) from
          `../editor/types.js`.

          3.  Create sample `NoMatchFailure` objects:
              *   One without a `closestMatch`.
              *   One with a `closestMatch`.
              *   One with very long `originalText` and `closestMatch.lines` to test trimming.
          4.  Create sample `NotUniqueFailure` objects:
              *   One with multiple `matchLocations`.
          5.  Write test cases:
              *   Test with an empty `failures` array (should return an empty string or a minimal message).
              *   Test with a single `NoMatchFailure` (without closest match). Verify the output format.
              *   Test with a single `NoMatchFailure` (with closest match). Verify the output format, including the diff.
              *   Test with a single `NotUniqueFailure`. Verify the output format, including locations and context.
              *   Test with a mix of failure types. Verify all are included correctly.
              *   Test the trimming logic for long text blocks.
        done: true
  - title: 3 - Parse rmfilter_command Tag
    description: >
      Implement functionality to extract the command-line arguments from the
      `<rmfilter_command>` tag potentially present in the LLM output content.
    files:
      - src/apply-llm-edits/apply.ts
      - src/rmfilter/utils.ts (new function)
    steps:
      - prompt: >
          In `src/rmfilter/utils.ts`:


          1.  Add a new exported function `parseCliArgsFromString(commandString:
          string): string[]`.

          2.  This function should take a string containing space-separated
          arguments, potentially with quoted arguments.

          3.  Implement logic to parse this string into an array of arguments,
          correctly handling arguments enclosed in single or double quotes. Be
          mindful of escaped quotes within quoted strings (e.g., `"arg with \"
          quote"`).

          4.  Return the parsed array of arguments.
        done: true
      - prompt: >
          Add unit tests for the `parseCliArgsFromString` function in
          `src/rmfilter/utils.ts`.


          1.  Create or update the test file `src/rmfilter/utils.test.ts`.

          2.  Import necessary modules: `describe`, `expect`, `it` from
          `bun:test`, and the `parseCliArgsFromString` function.

          3.  Write test cases covering various scenarios:
              *   Simple arguments without quotes.
              *   Arguments with double quotes.
              *   Arguments with single quotes.
              *   Arguments with escaped quotes inside quoted strings (e.g., `arg "with \"escaped\" quote"`).
              *   Mixed quoted and unquoted arguments.
              *   Empty string input.
              *   String with only whitespace.
              *   Arguments with special characters.
          4.  Assert that the function returns the expected array of arguments
          for each case.
        done: true
      - prompt: >
          In `src/apply-llm-edits/apply.ts`:


          1.  Import the `parseCliArgsFromString` function from
          `../rmfilter/utils.ts`.

          2.  Create a new internal helper function
          `extractRmfilterCommandArgs(content: string): string[] | null`.

          3.  This function should use a regular expression to find the content
          within the first `<rmfilter_command>` tag in the input `content`.

          4.  If the tag is found, extract its content.

          5.  Call `parseCliArgsFromString` with the extracted content.

          6.  Return the resulting array of arguments.

          7.  If the tag is not found or parsing fails (though
          `parseCliArgsFromString` should handle most cases), return `null`.

          8.  Add basic tests for `extractRmfilterCommandArgs` within
          `src/apply-llm-edits/apply.test.ts` (or a new file if preferred),
          mocking `parseCliArgsFromString` or testing the regex extraction
          logic. Test cases: tag present, tag absent, tag empty.
        done: true
  - title: 4 - Re-run rmfilter Programmatically
    description: >
      Create a function to execute the `rmfilter` script with specified
      arguments and capture its output. This is needed if the cached `rmfilter`
      output is deemed stale.
    files:
      - src/rmfilter/rmfilter.ts (new function)
      - src/rmfilter/utils.ts
    steps:
      - prompt: >
          Refactor `src/rmfilter/rmfilter.ts` to support programmatic execution.


          1.  Identify the core logic after argument parsing
          (`getCurrentConfig`) that performs file finding, document gathering,
          `repomix` calling, and final output assembly.

          2.  Extract this core logic into a new asynchronous function, let's
          call it `generateRmfilterOutput(config: RmfilterConfig, baseDir:
          string, gitRoot: string): Promise<string>`.
              *   `RmfilterConfig` should be a type representing the combined global and command-specific arguments needed by the core logic (derived from `globalValues` and `commandsParsed` structure). Define this type.
              *   This function should perform all the steps currently done in the main script body after parsing, using the provided `config` object instead of re-parsing `process.argv`.
              *   It should return the final generated string content.
          3.  Modify the main script execution block (at the end of the file)
          to:
              *   Call `getCurrentConfig` as before.
              *   Construct the `RmfilterConfig` object from the parsed results (`globalValues`, `commandsParsed`).
              *   Call `generateRmfilterOutput` with the config, `baseDir`, and `gitRoot`.
              *   Handle writing the output to file/clipboard based on the config.
          4.  Export the new `generateRmfilterOutput` function and the
          `RmfilterConfig` type.

          5.  Create a *new* function `runRmfilterProgrammatically(args:
          string[], gitRoot: string, baseDir: string): Promise<string>`.
              *   This function will simulate the CLI argument parsing for the given `args`. Use `parseArgs` internally on the provided `args` array, similar to how `getCurrentConfig` does, but without loading YAML presets directly (assume `args` contains the fully resolved configuration for this programmatic call). You might need to adapt parts of `getCurrentConfig`'s parsing logic.
              *   Construct the `RmfilterConfig` object from the parsed `args`.
              *   Call the refactored `generateRmfilterOutput` function with the constructed config, `baseDir`, and `gitRoot`.
              *   Return the result.
        done: true
      - prompt: >
          Add integration tests for the new `runRmfilterProgrammatically`
          function in `src/rmfilter/rmfilter.ts`.


          1.  Create a test file `src/rmfilter/rmfilter.test.ts`.

          2.  Import necessary modules: `test`, `expect`, `describe`,
          `beforeEach`, `afterEach`, `jest` from `bun:test`, and the
          `runRmfilterProgrammatically` function.

          3.  Set up a temporary directory structure with mock files for testing
          (e.g., using `fs` module within `beforeEach`/`afterEach`). Include
          files that can be found by globs or grep.

          4.  Mock external dependencies like `callRepomix`,
          `getAdditionalDocs`, `getDiffTag`, `buildExamplesTag` to return
          predictable strings or structures.

          5.  Mock file system reads (`Bun.file().text()`,
          `Bun.file().exists()`) as needed for the core logic within
          `generateRmfilterOutput` (which `runRmfilterProgrammatically` calls).

          6.  Write test cases for `runRmfilterProgrammatically`:
              *   Pass simple arguments (e.g., just a file path). Verify the mocked `generateRmfilterOutput` (or its components like `callRepomix`) receives expected inputs based on the arguments.
              *   Pass arguments including `--grep`, `--docs`, etc. Verify the core logic receives the correct configuration.
              *   Check that the function returns the expected output string assembled by the (mocked) core logic.
              *   Test error handling if argument parsing fails (if applicable within the function).
        done: true
  - title: 5 - Retrieve Original Prompt Context
    description: >
      Implement the logic within `applyLlmEdits` to determine the original
      prompt context, either by using a provided prompt, or by parsing the
      `rmfilter_command` tag and potentially re-running `rmfilter`.
    files:
      - src/apply-llm-edits/apply.ts
      - src/rmfilter/rmfilter.ts (importing runRmfilterProgrammatically)
      - src/rmfilter/repomix.ts (importing getOutputPath)
      - src/rmfilter/utils.ts (importing getGitRoot)
    steps:
      - prompt: >
          Modify `src/apply-llm-edits/apply.ts`:


          1.  Import necessary functions:
              *   `extractRmfilterCommandArgs` from `./apply.ts` (or wherever it was placed).
              *   `runRmfilterProgrammatically` from `../rmfilter/rmfilter.ts`.
              *   `getOutputPath` from `../rmfilter/repomix.ts`.
              *   `getGitRoot` from `../rmfilter/utils.ts`.
              *   `Bun`, `path`.
              *   `debugLog`, `warn` from `../logging.ts`.
          2.  Add a new optional parameter `originalPrompt?: string` to the
          `ApplyLlmEditsOptions` interface and the `applyLlmEdits` function
          signature.

          3.  Define a new internal async function
          `getOriginalRequestContext(options: ApplyLlmEditsOptions, gitRoot:
          string, baseDir: string): Promise<string>`.

          4.  Inside `getOriginalRequestContext`:
              *   If `options.originalPrompt` is provided, return it directly.
              *   If not, call `extractRmfilterCommandArgs(options.content)` to get the arguments from the `<rmfilter_command>` tag.
              *   If no arguments are extracted, throw an error: "Cannot retry: Original prompt not provided and <rmfilter_command> tag not found in content."
              *   Get the expected path of the cached rmfilter output using `getOutputPath()`. Resolve it relative to `gitRoot`.
              *   Try to read the cached output file (e.g., `repomix-output.xml` or `repomix_output.txt`).
              *   If the cached file exists:
                  *   Extract the `<rmfilter_command>` tag content from the *cached file* as well.
                  *   Parse the arguments from the cached command tag.
                  *   Compare the arguments extracted from `options.content` with the arguments from the cached file's tag.
                  *   If the arguments match (order might not matter, consider sorting or using a set comparison), return the full content of the cached file.
                  *   If they don't match, log a warning that the cache is stale.
              *   If the cached file doesn't exist or the arguments didn't match:
                  *   Log that rmfilter needs to be re-run.
                  *   Call `runRmfilterProgrammatically` with the arguments extracted from `options.content`, `gitRoot`, and `baseDir`.
                  *   Return the output from `runRmfilterProgrammatically`.
              *   Handle potential errors during file reading or `runRmfilterProgrammatically` execution.
          5.  This function `getOriginalRequestContext` will be called later
          within the retry logic (Task 8). For now, just define it.
        done: true
      - prompt: >
          Add/update tests in `src/apply-llm-edits/apply.test.ts` for the
          `getOriginalRequestContext` function.


          1.  Import the necessary functions and types.

          2.  Mock dependencies:
              *   `extractRmfilterCommandArgs`: Mock to return specific args arrays or null.
              *   `getOutputPath`: Mock to return a predictable cache file path.
              *   `Bun.file().text()`: Mock file reads for both the input `content` and the cached output file. Return content with specific `<rmfilter_command>` tags or throw ENOENT.
              *   `runRmfilterProgrammatically`: Mock to return a specific string representing re-run output, or throw an error.
              *   `getGitRoot`: Mock if needed.
          3.  Write test cases for `getOriginalRequestContext`:
              *   Test case where `options.originalPrompt` is provided (should return it directly).
              *   Test case where `rmfilter_command` is missing in `options.content` (should throw).
              *   Test case where cache file exists and arguments match (should return cached file content).
              *   Test case where cache file exists but arguments *don't* match (should call `runRmfilterProgrammatically` and return its result).
              *   Test case where cache file *doesn't* exist (should call `runRmfilterProgrammatically` and return its result).
              *   Test case where `runRmfilterProgrammatically` throws an error.
              *   Test argument comparison logic (ensure it handles different ordering if necessary, or assumes fixed order).
        done: true
  - title: 6 - Define LLM Requester Interface
    description: >
      Define a clear interface for how `applyLlmEdits` will request completions
      from an external LLM service. This involves adding a callback function to
      the options.
    files:
      - src/apply-llm-edits/apply.ts
      - src/apply-llm-edits/cmd.ts
    steps:
      - prompt: >
          In `src/apply-llm-edits/apply.ts`:


          1.  Define an interface for the structured LLM prompt, e.g.:
              ```typescript
              interface LlmPromptMessage {
                role: 'user' | 'assistant';
                content: string;
              }
              export type LlmPromptStructure = LlmPromptMessage[];
              ```
              (Place this near the top or in a relevant types section).
          2.  Define the type for the LLM requester callback function:
              ```typescript
              type LlmRequester = (prompt: LlmPromptStructure) => Promise<string>;
              ```
          3.  Add the optional `llmRequester?: LlmRequester` property to the
          `ApplyLlmEditsOptions` interface.

          4.  Update the `applyLlmEdits` function signature to accept the new
          `llmRequester` option from `ApplyLlmEditsOptions`.

          5.  No functional changes needed yet, just defining the interface and
          adding the option.


          In `src/apply-llm-edits/cmd.ts`:


          1.  Update the call to `applyLlmEdits` to pass `undefined` for the new
          `llmRequester` option for now. We are not implementing the CLI's LLM
          connection in this step.
        done: false
  - title: 7 - Construct Retry Prompt Structure
    description: >
      Create a function that assembles the structured prompt
      (User/Assistant/User messages) needed for the LLM retry request.
    files:
      - src/apply-llm-edits/apply.ts
      - src/apply-llm-edits/failures.ts (importing formatFailuresForLlm)
    steps:
      - prompt: >
          In `src/apply-llm-edits/apply.ts`:


          1.  Import the `LlmPromptStructure`, `LlmPromptMessage` types defined
          in the previous step.

          2.  Import `formatFailuresForLlm` from `./failures.ts`.

          3.  Import `NoMatchFailure`, `NotUniqueFailure` from
          `../editor/types.js`.

          4.  Create a new internal function `constructRetryPrompt`:
              ```typescript
              function constructRetryPrompt(
                originalRequestContext: string,
                failedLlmOutput: string,
                failures: (NoMatchFailure | NotUniqueFailure)[]
              ): LlmPromptStructure {
                // Function implementation
              }
              ```
          5.  Inside `constructRetryPrompt`:
              *   Call `formatFailuresForLlm(failures)` to get the formatted failure description string.
              *   Create the final user message content. This should include the formatted failure description and clear instructions for the LLM, for example:
                  ```text
                  The previous attempt to apply the edits resulted in the following errors:

                  ${formattedFailures}

                  Please review the original request context, your previous response, and the errors listed above. Provide a corrected set of edits in the same format as before, addressing these issues. Ensure the SEARCH blocks exactly match the current file content where the changes should be applied, or provide correct unified diffs.
                  ```
              *   Construct the `LlmPromptStructure` array:
                  *   Message 1: `{ role: 'user', content: originalRequestContext }`
                  *   Message 2: `{ role: 'assistant', content: failedLlmOutput }`
                  *   Message 3: `{ role: 'user', content: finalUserMessageContent }`
              *   Return the constructed array.
        done: false
      - prompt: >
          Add unit tests in `src/apply-llm-edits/apply.test.ts` for the
          `constructRetryPrompt` function.


          1.  Import necessary functions and types, including
          `constructRetryPrompt`, `LlmPromptStructure`, failure types, and mock
          `formatFailuresForLlm`.

          2.  Mock `formatFailuresForLlm` to return a predictable string based
          on the input failures.

          3.  Write test cases:
              *   Provide sample `originalRequestContext`, `failedLlmOutput`, and an array of mock `failures`.
              *   Call `constructRetryPrompt`.
              *   Verify that the returned `LlmPromptStructure` has the correct length (3 messages).
              *   Verify the `role` and `content` of each message match the expected structure (user/assistant/user).
              *   Verify that the content of the final user message includes the mocked output from `formatFailuresForLlm` and the instructional text.
        done: false
  - title: 8 - Implement Retry Loop in applyLlmEdits
    description: >
      Integrate all the previous steps into the main `applyLlmEdits` function to
      implement the retry logic.
    files:
      - src/apply-llm-edits/apply.ts
      - src/apply-llm-edits/interactive.ts
      - src/logging.ts
    steps:
      - prompt: >
          Modify the `applyLlmEdits` function in `src/apply-llm-edits/apply.ts`:


          1.  Import necessary functions/types: `applyEditsInternal`,
          `getOriginalRequestContext`, `constructRetryPrompt`, `LlmRequester`,
          `LlmPromptStructure`, `EditResult`, failure types,
          `resolveFailuresInteractively`, `printDetailedFailures`, `log`,
          `error`.

          2.  After the initial call to `applyEditsInternal` and the handling of
          auto-applied `notUnique` failures (resulting in `remainingFailures`),
          add the retry logic:

          3.  Check if `remainingFailures.length > 0` AND if
          `options.llmRequester` is provided.

          4.  If both conditions are true:
              *   Log that initial application failed and a retry attempt will be made.
              *   Call `getOriginalRequestContext(options, writeRoot, baseDir)` (you'll need `baseDir` calculated similarly to how `rmfilter.ts` does, or passed into `applyLlmEdits`). Handle potential errors from this call (e.g., wrap in try/catch). If it fails, log an error and proceed as if no retry was possible.
              *   Call `constructRetryPrompt(originalContext, options.content, remainingFailures)` to get the retry prompt structure.
              *   Log that a request is being sent to the LLM for corrections.
              *   Call `options.llmRequester(retryPrompt)` and await the `retryResponseContent` string. Handle potential errors from the LLM request. If it fails, log an error and proceed as if no retry was possible.
              *   Log that the retry response has been received.
              *   Call `applyEditsInternal` again, but this time with `retryResponseContent` as the `content`. Pass the same `writeRoot`, `dryRun`, and `mode`.
              *   Store the results of this second call in a new variable, e.g., `retryResults`.
              *   Re-calculate the failures from `retryResults`. Handle auto-applied `notUnique` failures again for the retry results, storing the final failures in `finalFailures`.
              *   Log whether the retry attempt was successful or if failures remain.
              *   Replace the original `remainingFailures` with `finalFailures`.
          5.  After the retry block (or if the retry conditions were not met),
          check `remainingFailures.length` again.

          6.  If failures still exist:
              *   Check `options.interactive`. If true, call `resolveFailuresInteractively(remainingFailures, writeRoot, options.dryRun ?? false)`.
              *   If not interactive, call `printDetailedFailures(remainingFailures)` and throw the error `Failed to apply ${remainingFailures.length} edits...`.
          7.  If no failures remain (either initially or after retry), log that
          all edits were applied successfully.

          8.  Ensure `baseDir` is correctly determined or passed into
          `applyLlmEdits`. It's needed for `getOriginalRequestContext`. You
          might need to add `baseDir?: string` to `ApplyLlmEditsOptions` and
          calculate it in `cmd.ts` or the primary caller. For now, assume it's
          available. Let's add it: Modify `ApplyLlmEditsOptions` to include
          `baseDir?: string`. Update `applyLlmEdits` signature. Calculate
          `baseDir` in `cmd.ts` using the logic from `rmfilter.ts`
          (`calculateBaseDir`) and pass it.
        done: false
      - prompt: >
          Update integration tests in `src/apply-llm-edits/apply.test.ts` to
          cover the retry logic in `applyLlmEdits`.


          1.  Import necessary mocks and functions.

          2.  Mock `applyEditsInternal`. Make it return different results based
          on call count or input content (e.g., return failures on the first
          call, success on the second).

          3.  Mock `getOriginalRequestContext` to return a sample context
          string.

          4.  Mock `constructRetryPrompt` (or verify its inputs).

          5.  Mock `resolveFailuresInteractively` and `printDetailedFailures`.

          6.  Create mock `LlmRequester` functions:
              *   One that returns a "corrected" content string.
              *   One that simulates an error.
          7.  Write test cases for `applyLlmEdits`:
              *   Scenario: Initial application fails, `llmRequester` is provided, retry request is made, `applyEditsInternal` succeeds on the second call. Verify success logs.
              *   Scenario: Initial application fails, `llmRequester` is provided, retry request is made, `applyEditsInternal` *still* fails on the second call, `interactive` is false. Verify `printDetailedFailures` is called and error is thrown.
              *   Scenario: Initial application fails, `llmRequester` is provided, retry request is made, `applyEditsInternal` *still* fails on the second call, `interactive` is true. Verify `resolveFailuresInteractively` is called.
              *   Scenario: Initial application fails, `llmRequester` is *not* provided, `interactive` is false. Verify `printDetailedFailures` is called and error is thrown immediately.
              *   Scenario: Initial application fails, `llmRequester` is *not* provided, `interactive` is true. Verify `resolveFailuresInteractively` is called immediately.
              *   Scenario: `getOriginalRequestContext` throws an error during retry. Verify retry is aborted and fallback (interactive/throw) occurs.
              *   Scenario: `llmRequester` throws an error during retry. Verify retry is aborted and fallback occurs.
              *   Scenario: Initial application succeeds. Verify no retry logic is triggered.
        done: false
  - title: 9 - CLI Integration (Optional)
    description: >
      Update the CLI command (`cmd.ts`) to potentially support the new retry
      feature, although the core logic is in the library function. This might
      involve adding flags or configuring how the LLM requester is obtained.
      *Note: Full LLM integration in the CLI is complex and might be out of
      scope for this plan.*
    files:
      - src/apply-llm-edits/cmd.ts
      - src/apply-llm-edits/apply.ts
    steps:
      - prompt: >
          Update `src/apply-llm-edits/cmd.ts`:


          1.  Import `getGitRoot` from `../rmfilter/utils.ts` and `path` from
          'node:path'.

          2.  Add CLI options parsing for:
              *   `--retry` (boolean)
              *   `--original-prompt <file_path>` (string)
          3.  Determine the `baseDir`: Use `await getWriteRoot(cwd)` which
          already incorporates `--cwd` and defaults to git root or
          `process.cwd()`. This should suffice for `baseDir` passed to
          `applyLlmEdits`.

          4.  Read original prompt: If `--original-prompt` is provided, read the
          content of the specified file path into a variable
          `originalPromptContent`. Handle file read errors.

          5.  Update the call to `applyLlmEdits`:
              *   Pass the determined `baseDir`.
              *   Pass `originalPromptContent` (or `undefined`) as the `originalPrompt` option.
              *   Pass `undefined` for the `llmRequester` option for now. The `--retry` flag currently serves only to indicate intent, but doesn't activate the LLM call from the CLI itself. Add a comment explaining this limitation.
        done: false
