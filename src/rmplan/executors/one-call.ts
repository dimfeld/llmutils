import { z } from 'zod/v4';
import type { ExecutorCommonOptions, Executor, ExecutorFactory } from './types';
import { DEFAULT_RUN_MODEL, runStreamingPrompt } from '../llm_utils/run_and_apply.js';
import { applyLlmEdits, type ApplyLlmEditsOptions } from '../../apply-llm-edits/apply';
import { log } from '../../logging';
import { createRetryRequester } from '../../apply-llm-edits/retry.ts';
import type { RmplanConfig } from '../configSchema.ts';
import { getGitRoot } from '../../common/git.ts';
import type { PrepareNextStepOptions } from '../plans/prepare_step.ts';
import { directCallOptionsSchema, OneCallExecutorName } from './schemas.js';

export type OneCallExecutorOptions = z.infer<typeof directCallOptionsSchema>;

/**
 * The 'direct-call' executor.
 * This executor generates context using `rmfilter` and then directly calls an LLM
 * with that context. The LLM's response is then processed by `applyLlmEdits`.
 */
export class OneCallExecutor implements Executor {
  static name = OneCallExecutorName;
  static description =
    'Executes the plan by directly calling an LLM with context generated by rmfilter, then applies edits.';
  static optionsSchema = directCallOptionsSchema;

  constructor(
    public options: OneCallExecutorOptions,
    public sharedOptions: ExecutorCommonOptions,
    public rmplanConfig: RmplanConfig
  ) {}

  get executionModel() {
    return (
      this.rmplanConfig.models?.execution ??
      this.options.executionModel ??
      this.sharedOptions.model ??
      DEFAULT_RUN_MODEL
    );
  }

  prepareStepOptions() {
    const options: Partial<PrepareNextStepOptions> = {
      rmfilter: true,
      // improves caching
      rmfilterArgs: ['--omit-top-instructions'],
      model: this.executionModel,
    };

    return options;
  }

  async execute(contextContent: string) {
    const retryRequester = createRetryRequester(this.executionModel);
    const { text: llmOutput } = await runStreamingPrompt({
      input: contextContent,
      model: this.executionModel,
      temperature: 0,
      // Temperature and other LLM params could be configurable here or via rmplanConfig/executorOptions in future
    });

    // Add a newline for better separation in logs if streaming to console
    if (!process.stdout.isTTY) {
      // A simple check, or could be based on a quiet flag
      log('');
    }

    await applyLlmEdits({
      interactive: true,
      baseDir: await getGitRoot(this.sharedOptions.baseDir),
      content: llmOutput,
      retryRequester: retryRequester,
      originalPrompt: contextContent, // Pass the rmfilter output as the original prompt for retries
    });
  }
}
